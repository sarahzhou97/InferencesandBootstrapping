---
title: "HW3"
author: "Sarah Zhou"
date: "11/9/2015"
output: html_document
---

**Part 1: Sampling distribution of the sample proportion**

Loading the libraries
```{r libraries}
library(dplyr)
library(ggplot2)
library(stringr)
library(GGally)
```

1. Loading dataset
```{r load-pops}
pops <- read.csv("https://stat.duke.edu/~mc301/data/cat_pops.csv")
```

2 and 3. Creating sampling distributions and describing their shape

```{r sampling-function}
sampling <- function(data = NULL, nsample = NULL, seed = NULL,
                     n_sim = NULL, success = NULL) {
  set.seed(seed)
  pop_data <- data.frame(sample_prop_success = rep(NA, n_sim))
  
  for (i in 1:n_sim) {
    sim <- sample(data, size = nsample, replace = TRUE)
    samp_prop_success <- sum(sim == success)/length(sim)
    pop_data$sample_prop_success[i] <- samp_prop_success
  }
  
  histogram <- ggplot(pop_data,aes(x = sample_prop_success)) +
    geom_histogram() +
    ggtitle(paste("Sampling Distribution of Sample Size",nsample))
  
  norm_prob_plot <- ggplot(data = pop_data,aes(sample = sample_prop_success)) +
    geom_point(stat = "qq") +
    ggtitle(paste("Normal Probability Plot of Sample Size",nsample))
   
  summary <- pop_data %>%
    summarise(mean = mean(sample_prop_success), median = median(sample_prop_success),
              sd = sd(sample_prop_success))
  
  print(histogram)
  print(norm_prob_plot)
  return(summary)
}
```

_For very low success rate data_
```{r sample-n10}
sampling(data = pops$p_very_low, nsample = 10, seed = 3948, n_sim = 15000, 
         success = "success")
sampling(data = pops$p_very_low, nsample = 50, seed = 3348, n_sim = 15000, 
         success = "success")
sampling(data = pops$p_very_low, nsample = 200, seed = 3647, n_sim = 15000, 
         success = "success")
```

_For low success rate data_
```{r}
sampling(data = pops$p_low, nsample = 10, seed = 3487, n_sim = 15000, success = "success")
sampling(data = pops$p_low, nsample = 50, seed = 3797, n_sim = 15000, success = "success")
sampling(data = pops$p_low, nsample = 200, seed = 3687, n_sim = 15000, success = "success")
```

_For medium success rate data_
```{r}
sampling(data = pops$p_med, nsample = 10, seed = 3417, n_sim = 15000, success = "success")
sampling(data = pops$p_med, nsample = 50, seed = 3410, n_sim = 15000, success = "success")
sampling(data = pops$p_med, nsample = 200, seed = 2417, n_sim = 15000, success = "success")
```

_For high success rate data_
```{r}
sampling(data = pops$p_high, nsample = 10, seed = 3418, n_sim = 15000, success = "success")
sampling(data = pops$p_high, nsample = 50, seed = 3430, n_sim = 15000, success = "success")
sampling(data = pops$p_high, nsample = 200, seed = 2917, n_sim = 15000, success = "success")
```

  As expected, both the histograms of the sampling distributions and the Normal Probability Plots of all four data sets show that as sample size increases, the data becomes closer to a Normal distribution. The sample distribution curves start to look more similar to a Normal distribution curve and the Normal Probability Plots look more linear. This trend is particularly more noticeable the more skewed the data is (eg. particularly more for the populations with very low probability of success and high probability of success), as the sample distribution cruve and Normal Probability Plot one for the medium probability of success looked pretty close to that of a Normal distribution with even a sample size of 10 whereas the graphs for the two most skewed data didn't look similar a Normal distribution until the sample size was increased to 200. 
  
  In other words, as sample sizes increase, the different populations become more similar because they all become more similar to a Normal distribution. This is due to the Central Limit Theorem, which states that the distribution of of a large number of independent, identically distributed variables will be approximately normal, regardless of the underlying distribution.
  
**Part 2: Inference**

Loading dataset
```{r}
gss <- read.csv("https://stat.duke.edu/~mc301/data/gss2010.csv", stringsAsFactors = FALSE)
```

1. Working extra: 

m = true mean number of days per month Americans work overtime

$H_0: m = 5$

$H_A: m > 5$

Summary Stats:
```{r}
moredays_summ <- gss %>%
  filter(!is.na(moredays)) %>%
  summarise(xbar=mean(moredays),sd=sd(moredays),n=length(moredays))

moredays_summ
```

Hypothesis Test:
```{r}
#calculations
standard_error <- moredays_summ$sd/sqrt(moredays_summ$n)
t <- (moredays_summ$xbar-5)/standard_error
df <- moredays_summ$n-1

#p-value
pt(t,df,lower.tail = FALSE)

#P-value from t.test function:
t.test(x = gss$moredays, alternative="greater", mu = 5)
```
  Our p-value of 0.000734 is less than our significance level of 0.05; thus, we reject our null hypothesis. We have convincing evidence to suggest that Americans, on average, work overtime more than 5 days per month. 
  
Confidence Interval:
```{r}
t_star <- qt(0.95, df) 
pt_est <- moredays_summ$xbar
round(pt_est + c(-1,1) * t_star * standard_error, 3)

"Confidence Interval from t.test function:"
t.test(x = gss$moredays, conf.level = 0.9)$conf.int
```

  I am 90% confident that the true mean number of days Americans work overtime per month is between 5.344 and 6.078. This is consistent with my Hypothesis Test, as I rejected the null hypothesis; thus, 5, the number stated in my null hypothesis, is not contained in the confidence interval.
  
2. Working extra and education: 

$m_1$: true mean number of days worked by Americans with college education each month 

$m_2$: true mean number of days worked by Americans without college education each month 

$H_0: m_{1}=m_{2}$

$H_A: m_{1}!=m_{2}$

Mutating Degree variable to make it binary:
```{r}
gss <- gss %>%
  mutate(degree_recode = ifelse(degree %in% c("Don't know","No answer"),NA,
                                ifelse(degree %in% c("GRADUATE","BACHELOR","JUNIOR COLLEGE"),"college",
                                       ifelse(degree %in% c("HIGH SCHOOL","LT HIGH SCHOOL"),"no college",degree))))
```

Summary statistics:
```{r}
moredays_education_summ <- gss %>%
  filter(!is.na(moredays)) %>%
  group_by(degree_recode) %>%
  summarise(xbar=mean(moredays), sd = sd(moredays), n = length(moredays)) 

moredays_education_summ
```

Calculations:
```{r}
standard_error <- sqrt((moredays_education_summ$sd[1]^2)/(moredays_education_summ$n[1])+(moredays_education_summ$sd[2]^2)/(moredays_education_summ$n[2]))
t <- (moredays_education_summ$xbar[1]-moredays_education_summ$xbar[2])/standard_error
df <- min(moredays_education_summ$n[1],moredays_education_summ$n[2])-1
```

Hypothesis Test:
```{r}
#P-value
#divide p-value by 2 because two-sided test
p_value <- (pt(t,df,lower.tail = FALSE))/2
p_value

#P-value from t.test function:
t.test(x = gss$moredays, alternative="two.sided", mu = 0)
```

  Our p-value of 2.2e-16 is less than our significance level of 0.05; thus, we reject the null hypothesis. There is convincing evidence to suggest that there is a difference in average number of days worked overtime based on whether or not you have a college degree or not. 
  
Confidence Interval:
```{r}
t_star <- qt(0.95, df) 
pt_est <- moredays_summ$xbar
round(pt_est + c(-1,1) * t_star * standard_error, 3)


"Confidence Interval from t.test function:"
t.test(x = gss$moredays, conf.level = 0.95)$conf.int
```

  I am 95% confident that the true difference in mean number of days overworked per month between those who have college degrees and those who don't is between 5.273 and 6.148. This interval doesn't include 0, the value stated in our null hypthosis, which makes sense since we rejected our null hypothesis in our hypothesis test.

3. Life after death

Mutate variable to eliminate "Don't Answer" and "No Answer"
```{r}
gss <- gss %>%
  mutate(postlife_recode = ifelse(postlife %in% c("DON'T KNOW","NO ANSWER"),NA,postlife))
```

Summary Stats:
```{r}
postlife_summ <- gss %>%
  filter(!is.na(postlife_recode)) %>%
  summarise(x=sum(postlife_recode=="YES"),n=length(postlife_recode),p_hat=x/n)

postlife_summ
```

Confidence interval using CLT:
```{r}
#calculations
standard_error <- sqrt(postlife_summ$p_hat*(1-postlife_summ$p_hat)/postlife_summ$n)

#Confidence Interval
z_star <- qnorm(0.975)
round(postlife_summ$p_hat + c(-1,1) * z_star * standard_error, 3)

"Confidence Interval from t.test function:"
prop.test(postlife_summ$x, postlife_summ$n, conf.level = 0.95, correct = FALSE)$conf.int
```

  I am 95% confident that the true proportion of Americans who believe in life after death is between 0.715 and 0.906. 
  
Confidence interval using bootstrapping:
```{r}
set.seed(4958347)
nsim = 15000
postlife_dist = data.frame(stat = rep(NA, nsim))

for(i in 1:nsim) {
  postlife_sample = sample(gss$postlife_recode, size = 200, replace = TRUE)
  postlife_dist$stat[i] = sum(postlife_sample == "YES")/200
}

stat = sum(gss$postlife == "YES") / postlife_summ$n
se_boot = sd(postlife_dist$stat)
boot_int = round(stat + c(-1,1) * 1.96 * se_boot, 3)

boot_int
```

  The confidence interval I got from the bootstrapping method is close to the one I got from the CLT method but it is narrower because my sample size is quite large (200), which decreases Standard Error, and thus the interval as well.
  
4. Pick your own

Question: Is the proportion of Americans who are satisfied with their financial status different greater if they were born in the US than if they were not?

$p_{US_born} = true proportion of US-born Americans who are satisfied with their financial status$

$p_{not_US_born} = true proportion of non-US-born Americans who are satisfied with their financial status$

$H_0: p_{US_born} - p_{not_US_born} = 0$

$H_A: p_{US_born} - p_{not_US_born} > 0$

Mutating variables to make them binary:
```{r}
gss <- gss %>%
  mutate(born_recode = ifelse(born %in% c("NO ANSWER","NOT APPLICABLE","DON'T KNOW"),NA,born))

gss <- gss %>%
  mutate(satfin_recode = ifelse(satfin %in% c("DON'T KNOW", "NO ANSWER", "MORE OR LESS"),NA,
                               ifelse(satfin == "SATISFIED","satisfied",
                                      ifelse(satfin == "NOT AT ALL SAT", "not satisfied",satfin))))
```                      

Summary statistics:
```{r}
satfin_born_summ <- gss %>%
  filter(!is.na(born_recode)) %>%
  filter(!is.na(satfin_recode)) %>%
  group_by(born_recode) %>%
  summarise(x=sum(satfin_recode=="satisfied"),n=length(satfin_recode),p_hat=x/n)

satfin_born_summ
```

Hypothesis Test:
```{r}
#Pooled proportion

total_satisfied <- sum(satfin_born_summ$x)
total_n <- sum(satfin_born_summ$n)
p_pool <- total_satisfied / total_n

p_pool

#Calculating test statistic

se <- sqrt(p_pool * (1-p_pool)/satfin_born_summ$n[2] + p_pool * (1-p_pool)/satfin_born_summ$n[1])
z <- (satfin_born_summ$p_hat[2] - satfin_born_summ$p_hat[1] - 0 / se)
z

#p-value
pnorm(z,lower.tail=FALSE)
```

  My p-value of 0.483 is greater than my significance level of 0.05; thus, we fail to reject the null hypothesis. There is not convincing evidence to suggest that there is a difference in proportion of people who are satisifed with their financial situation based on whether or not they were born in the US or not. 
  
Confidence Interval:
```{r}
se <- sqrt((satfin_born_summ$p_hat[2] * (1-satfin_born_summ$p_hat[2])/satfin_born_summ$n[2]) + (satfin_born_summ$p_hat[1] * (1-satfin_born_summ$p_hat[1])/satfin_born_summ$n[1]))
z_star <- qnorm(0.975)
pt_est <- satfin_born_summ$p_hat[2] - satfin_born_summ$p_hat[1]
round(pt_est + c(-1,1) * z_star * se, 3)

"Confidence Interval from t.test function:"
prop.test(x = c(satfin_born_summ$x[2], satfin_born_summ$x[1]), n = c(satfin_born_summ$n[2], satfin_born_summ$n[1]),conf.level = 0.95, correct = FALSE)$conf.int
```

  I am 95% confident that the true difference in proportion of people who are born in the US and satisfied with their financial situation and people who are not born in the US and satisfied with their financial situation is between -0.048 and 0.133. This interval includes 0, the value in our null hypothesis, which makes sense since we failed to reject our null hypothesis in the hypothesis test. 

**Part 3: Extra Credit**

Loading data
```{r}
zinc <- read.csv("https://stat.duke.edu/~mc301/data/zinc.csv", stringsAsFactors = FALSE)
```

Hypothesis Testing using 5% signficance level:

$m_1$ = zinc concentration in bottom water

$m_2$ = zinc concentration in surface water

$H_0: m_1 - m_2 = 0$

$H_A: m_1 - m_2 > 0$ 

Create new variable diff = zinc concentration in bottom water - zinc concentration in surface water

```{r}
diff <- zinc$bottom - zinc$surface
```

Summary Statistics for diff:
```{r}
diff_summ <- zinc %>%
  summarise(xbar=mean(diff),sd=sd(diff),n=length(diff))

diff_summ
```

Hypothesis Test:
```{r}
#calculations
standard_error <- diff_summ$sd/sqrt(diff_summ$n)
t <- (diff_summ$xbar-0)/standard_error
df <- diff_summ$n-1

#p-value
p_value <- (pt(t,df,lower.tail = FALSE))
p_value

"P-value from t.test function:"
t.test(x = zinc$bottom, y = zinc$surface, alternative="greater", paired = TRUE, mu = 0)
```

  My p-value of 0.000446 is less than our significance level of 0.05; thus, we reject our null hypothesis. There is convincing evidence to suggest that the concentration of trace metals in bottom water is greater than the concentration in surface water.